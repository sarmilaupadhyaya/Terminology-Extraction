Abstract Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation NMT models . In this paper we propose to improve the robustness of NMT models with adversarial stability training . The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart . Experimental results on and translation tasks show that our approaches cannot only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models . 1 Introduction Neural machine translation NMT models have advanced the state of the art by building a single neural network that can better learn representations Cho et 2014 Sutskever et 2014 . The neural network consists of two components: an encoder network that encodes the input sentence into a sequence of distributed representations based on which a decoder network generates the translation with an attention model Bahdanau et 2015 Luong et 2015 . A variety of NMT models derived from this framework have further improved the performance of machine translation systems Gehring et 2017 Vaswani et 2017 . NMT is capable of generalizing better to unseen text by exploiting word similarities in embeddings and capturing reordering by conditioning on larger contexts in a continuous way . Input tamen bupa kunnan zuochu weiqi AI . Output They are not afraid of difficulties to make Go AI . Input tamen buwei kunnan zuochu weiqi AI . Output They are not afraid to make Go AI . Table 1: The problem of neural machine translation . Replacing a Chinese word with its synonym bupa buwei leads to significant erroneous changes in the English translation . Both bupa and buwei can be translated to the English phrase be not afraid However studies reveal that very small changes to the input can fool neural networks with high probability Goodfellow et 2015 Szegedy et 2014 . Belinkov and Bisk 2018 confirm this finding by pointing out that NMT models are very brittle and easily falter when presented with noisy input . In NMT due to the introduction of RNN and attention each contextual word can influence the model prediction in a global context which is analogous to the butterfly As shown in Table 1 although we only replace a source word with its synonym the generated translation has been completely distorted . We investigate severe variations of translations caused by small input perturbations by replacing one word in each sentence of a test set with its synonym . We observe that of translations have changed and the BLEU score is only between the translations of the original inputs and the translations of the perturbed inputs suggesting that NMT models are very sensitive to small perturbations in the input . The vulnerability and instability of NMT models limit their applicability to a broader range of tasks which require robust performance on noisy inputs . For example simultaneous translation systems use 1757 matic speech recognition ASR to transcribe input speech into a sequence of hypothesized words which are subsequently fed to a translation system . In this pipeline ASR errors are presented as sentences with noisy perturbations the same pronunciation but incorrect words which is a significant challenge for current NMT models . Moreover instability makes NMT models sensitive to misspellings and typos in text translation . In this paper we address this challenge with adversarial stability training for neural machine translation . The basic idea is to improve the robustness of two important components in NMT: the encoder and decoder . To this end we propose two approaches to constructing noisy inputs with small perturbations to make NMT models resist them . As important intermediate representations encoded by the encoder they directly determine the accuracy of final translations . We introduce adversarial learning to make behaviors of the encoder consistent for both an input and its perturbed counterpart . To improve the stability of the decoder our method jointly maximizes the likelihoods of original and perturbed data . Adversarial stability training has the following advantages : 1 . Improving both the robustness and translation performance: Our adversarial stability training is capable of not only improving the robustness of NMT models but also achieving better translation performance . 2 . Applicable to arbitrary noisy perturbations: In this paper we propose two approaches to constructing noisy perturbations for inputs . However our training framework can be easily extended to arbitrary noisy perturbations . Especially we can design perturbation methods . 3 . Transparent to network architectures: Our adversarial stability training does not depend on specific NMT architectures . It can be applied to arbitrary NMT systems . Experiments on EnglishFrench and translation tasks show that adversarial stability training achieves significant improvements across different languages pairs . Our NMT system outperforms the NMT system GNMT Wu et 2016 and obtains comparable performance with the NMT system Gehring et 2017 . Related experimental analyses validate that our training approach can improve the robustness of NMT models . 2 Background NMT is an framework which directly optimizes the translation probability of a target sentence y y1 yN given its corresponding source sentence x x1 xM: P θ Y N P n x θ 1 where θ is a set of model parameters and y n is a partial translation . P θ is defined on a holistic neural network which mainly includes two core components: an encoder encodes a source sentence x into a sequence of hidden representations Hx H1 HM and a decoder generates the target word based on the sequence of hidden representations: P n x θ exp g sn Hx θ 2 where sn is the hidden state on target side . Thus the model parameters of NMT include the parameter sets of the encoder θenc and the decoder θdec: θ θenc θdec . The standard training objective is to minimize the negative of the training corpus S hx s y s i: θˆ argmin θ L x y θ argmin θ n X hx log P θ o 3 Due to the vulnerability and instability of deep neural networks NMT models usually suffer from a drawback: small perturbations in the input can dramatically deteriorate its translation results . Belinkov and Bisk 2018 point out that characterbased NMT models are very brittle and easily falter when presented with noisy input . We find that and NMT models also confront with this shortcoming as shown in Table 1 . We argue that the distributed representations should fulfill the stability expectation which is the underlying concept of the proposed approach . Recent work has shown that adversarially trained models can be made robust to such perturbations Zheng et 2016 Madry et 2018 . Inspired by this in this work we improve the robustness of encoder representations against noisy perturbations with adversarial learning Goodfellow et 2014 . 1758 x x Encoder Hx Hx Discriminator Decoder Linv x x Ltrue x y Lnoisy x y Figure 1: The architecture of NMT with adversarial stability training . The dark solid arrow lines represent the information flow for the input sentence x while the red dashed arrow lines for the noisy input sentence x 0 which is transformed from x by adding small perturbations . 3 Approach Overview The goal of this work is to propose a general approach to make NMT models learned to be more robust to input perturbations . Our basic idea is to maintain the consistency of behaviors through the NMT model for the source sentence x and its perturbed counterpart x 0 . As aforementioned the NMT model contains two procedures for projecting a source sentence x to its target sentence y: the encoder is responsible for encoding x as a sequence of representations Hx while the decoder outputs y with Hx as input . We aim at learning the encoder and decoder . Figure 1 illustrates the architecture of our approach . Given a source sentence x we construct a set of perturbed sentences N x in which each sentence x 0 is constructed by adding small perturbations to x . We require that x 0 is a subtle variation from x and they have similar semantics . Given the input pair x x 0 we have two expectations : 1 the encoded representation Hx0 should be close to Hx and 2 given Hx0 the decoder is able to generate the robust output y . To this end we introduce two additional objectives to improve the robustness of the encoder and decoder: Linv x x 0 to encourage the encoder to output similar intermediate representations Hx and Hx0 for x and x 0 to achieve an invariant encoder which benefits outputting the same translations . We cast this objective in the adversarial learning framework . Lnoisy x 0 y to guide the decoder to generate output y given the noisy input x 0 which is modeled as log P 0 . It can also be defined as KL divergence between P and P 0 that indicates using P to teach P 0 . As seen the two introduced objectives aim to improve the robustness of the NMT model which can be free of high variances in target outputs caused by small perturbations in inputs . It is also natural to introduce the original training objective L x y on x and y which can guarantee good translation performance while keeping the stability of the NMT model . Formally given a training corpus S the adversarial stability training objective is J θ X hx Ltrue x y θenc θdec X x Linv x x 0 θenc θdis X x Lnoisy x 0 y θenc θdec 4 where Ltrue x y and Lnoisy x 0 y are calculated using Equation 3 and Linv x x 0 is the adversarial loss to be described in Section α and β control the balance between the original translation task and the stability of the NMT model . θ θenc θdec θdis are trainable parameters of the encoder decoder and the newly introduced discriminator used in adversarial learning . As seen the parameters of encoder θenc and decoder θdec are trained to minimize both the translation loss Ltrue x y and the stability losses Lnoisy x 0 y and Linv x x 0 . Since Lnoisy x 0 y evaluates the translation loss on the perturbed neighbour x 0 and its corresponding target sentence y it means that we augment the training data by adding perturbed neighbours which can potentially improve the translation performance . In this way our approach not only makes the output of NMT models more robust but also improves the performance on the original translation task . 1759 In the following sections we will first describe how to construct perturbed inputs with different strategies to fulfill different goals Section followed by the proposed adversarial learning mechanism for the encoder Section . We conclude this section with the training strategy Section . Constructing Perturbed Inputs At each training step we need to generate a perturbed neighbour set N x for each source sentence x for adversarial stability training . In this paper we propose two strategies to construct the perturbed inputs at multiple levels of representations . The first approach generates perturbed neighbours at the lexical level . Given an input sentence x we randomly sample some word positions to be modified . Then we replace words at these positions with other words in the vocabulary according to the following distribution: P exp cos E xi E x P exp cos E xi E x 5 where E xi is the word embedding for word xi is the source vocabulary set excluding the word xi and cos E xi E x measures the similarity between word xi and x . Thus we can change the word to another word with similar semantics . One potential problem of the above strategy is that it is hard to enumerate all possible positions and possible types to generate perturbed neighbours . Therefore we propose a more general approach to modifying the sentence at the feature level . Given a sentence we can obtain the word embedding for each word . We add the Gaussian noise to a word embedding to simulate possible types of perturbations . That is E x 0 i E xi N 0 σ2 I 6 where the vector is sampled from a Gaussian distribution with variance σ 2 . σ is a . We simply introduce Gaussian noise to all of word embeddings in x . The proposed scheme is a general framework where one can freely define the strategies to construct perturbed inputs . We just present two possible examples here . The first strategy is potentially useful when the training data contains noisy words while the latter is a more general strategy to improve the robustness of common NMT models . In practice one can design specific strategies for particular tasks . For example we can replace correct words with their homonyms same pronunciation but different meanings to improve NMT models for simultaneous translation systems . Adversarial Learning for the Encoder The goal of the encoder is to make the representations produced by the encoder indistinguishable when fed with a correct sentence x and its perturbed counterpart x 0 which is directly beneficial to the output robustness of the decoder . We cast the problem in the adversarial learning framework Goodfellow et 2014 . The encoder serves as the generator G which defines the policy that generates a sequence of hidden representations Hx given an input sentence x . We introduce an additional discriminator D to distinguish the representation of perturbed input Hx0 from that of the original input Hx . The goal of the generator G encoder is to produce similar representations for x and x 0 which could fool the discriminator while the discriminator D tries to correctly distinguish the two representations . Formally the adversarial learning objective is Linv x x 0 θenc θdis log D G x x log 1 D G x 0 7 The discriminator outputs a classification score given an input representation and tries to maximize D G x to 1 and minimize D G x 0 to 0 . The objective encourages the encoder to output similar representations for x and x 0 so that the discriminator fails to distinguish them . The training procedure can be regarded as a game . The encoder parameters θenc are trained to maximize the loss function to fool the discriminator . The discriminator parameters θdis are optimized to minimize this loss for improving the discriminating ability . For efficiency we update both the encoder and the discriminator simultaneously at each iteration rather than the periodical training strategy that is commonly used in adversarial learning . Lamb et al . 2016 also propose a similar idea to use Professor Forcing to make the behaviors of RNNs be indistinguishable when training and sampling the networks . 1760 Training As shown in Figure 1 our training objective includes three sets of model parameters for three modules . We use stochastic gradient descent to optimize our model . In the forward pass besides a of x and y we also construct a consisting of the perturbed neighbour x 0 and y . We propagate the information to calculate these three loss functions according to arrows . Then gradients are collected to update three sets of model parameters . Except for the gradients of Linv with respect to θenc are multiplying by other gradients are normally backpropagated . Note that we update θinv and θenc simultaneously for training efficiency . 4 Experiments Setup We evaluated our adversarial stability training on translation tasks of several language pairs and reported the BLEU Papineni et 2002 score as calculated by the script . We used the LDC corpus consisting of sentence pairs with Chinese words and English words respectively . We selected the best model using the NIST 2006 set as the validation set optimization and model selection . The NIST 2002 2003 2004 2005 and 2008 datasets are used as test sets . We used the WMT 14 corpus containing sentence pairs with 118M English words and 111M German words . The validation set is newstest2013 and the test set is newstest2014 . We used the IWSLT corpus which contains sentence pairs with English words and French words . The IWLST corpus is very dissimilar from the NIST and WMT corpora . As they are collected from TED talks and inclined to spoken language we want to verify our approaches on the nonnormative text . The IWSLT 14 test set is taken as the validation set and 15 test set is used as the test set . For and we tokenize both English German and French words using script . We follow Sennrich et al . 2016b to split words into subword units . The numbers of merge operations in byte pair encoding BPE are set to 30K 40K and 30K respectively for and . We report the tokenized BLEU score for and and the caseinsensitive tokenized BLEU score for ChineseEnglish . Our baseline system is an NMT system . Following Bahdanau et al . 2015 we implement an NMT in which both the encoder and decoder are RNNs with residual connections between layers He et 2016b . The gating mechanism of RNNs is gated recurrent unit GRUs Cho et 2014 . We apply layer normalization Ba et 2016 and dropout Hinton et 2012 to the hidden states of GRUs . Dropout is also added to the source and target word embeddings . We share the same matrix between the target word embeedings and the linear transformation Vaswani et 2017 . We update the set of model parameters using Adam SGD Kingma and Ba 2015 . Its learning rate is initially set to and varies according to the formula in Vaswani et al . 2017 . Our adversarial stability training initializes the model based on the parameters trained by maximum likelihood estimation MLE . We denote adversarial stability training based on perturbations and perturbations respectively as ASTlexical and ASTfeature . We only sample one perturbed neighbour x 0 N x for training efficiency . For the discriminator used in Linv we adopt the CNN discriminator proposed by Kim 2014 to address the problem of the sequence generated by the encoder . In the CNN discriminator the filter windows are set to 3 4 5 and rectified linear units are applied after convolution operations . We tune the hyperparameters on the validation set through a grid search . We find that both the optimal values of α and β are set to . The standard variance in Gaussian noise used in the formula 6 is set to . The number of words that are replaced in the sentence x during perturbations is taken as max 1 in which is the length of x . The default beam size for decoding is 10 . Translation Results NIST Translation Table 2 shows the results on translation . Our strong baseline system significantly outperforms previously reported results on 1761 System Training MT06 MT02 MT03 MT04 MT05 MT08 Shen et al . 2016 MRT Wang et al . 2017 MLE Zhang et al . 2018 MLE this work MLE ASTlexical ASTfeature Table 2: BLEU scores on translation . System Architecture Training BLEU Shen et al . 2016 Gated RNN with 1 layer MRT Luong et al . 2015 LSTM with 4 layers MLE Kalchbrenner et al . 2017 ByteNet with 30 layers MLE Wang et al . 2017 DeepLAU with 4 layers MLE Wu et al . 2016 LSTM with 8 layers RL Gehring et al . 2017 CNN with 15 layers MLE Vaswani et al . 2017 with 6 layers MLE this work Gated RNN with 2 layers MLE ASTlexical ASTfeature Table 3: BLEU scores on WMT 14 translation . Training tst2014 tst2015 MLE ASTlexical ASTfeature Table 4: BLEU scores on IWSLT translation . NIST datasets trained on RNNbased NMT . Shen et al . 2016 propose minimum risk training MRT for NMT which directly optimizes model parameters with respect to BLEU scores . Wang et al . 2017 address the issue of severe gradient diffusion with linear associative units LAU . Their system is deep with an encoder of 4 layers and a decoder of 4 layers . Zhang et al . 2018 propose to exploit both and decoding strategies for NMT to capture bidirectional dependencies . Compared with them our NMT system trained by MLE outperforms their best models by around 3 BLEU points . We hope that the strong baseline systems used in this work make the evaluation convincing . We find that introducing adversarial stability training into NMT can bring substantial improvements over previous work up to BLEU points over Shen et al . 2016 up to BLEU points over Wang et al . 2017 and up to BLEU points over Zhang et al . 2018 and our system trained with MLE across all the datasets . Compared with our baseline system ASTlexical achieves BLEU improvement on average . ASTfeature performs better which can obtain BLEU points on average and up to BLEU points on NIST08 . WMT 14 Translation In Table 3 we list existing NMT systems as comparisons . All these systems use the same WMT 14 corpus . Except that Shen et al . 2016 and Wu et al . 2016 respectively adopt MRT and reinforcement learning RL other systems all use MLE as training criterion . All the systems except for Shen et al . 2016 are deep NMT models with no less than four layers . Google s neural machine translation GNMT Wu et 2016 represents a strong NMT system . Compared with other NMT systems except for GNMT our baseline system with two layers can achieve better performance than theirs . When training our NMT system with ASTleixcal significant improvement 1762 Synthetic Type Training 0 Op . 1 Op . 2 Op . 3 Op . 4 Op . 5 Op . Swap MLE ASTlexical ASTfeature Replacement MLE ASTlexical ASTfeature Deletion MLE ASTlexical ASTfeature Table 5: Translation results of synthetic perturbations on the validation set in translation . 1 denotes that we conduct one operation swap replacement or deletion on the original sentence . Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing Reference china s new management rules for operations to take effect on march 1 MLE china s electronic bank rules to be implemented on march 1 ASTlexical new rules for business administration of china s electronic banking industry will come into effect on march 1 . ASTfeature new rules for business management of china s electronic banking industry to come into effect on march 1 Perturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing MLE china to implement new regulations on business management ASTlexical the new regulations for the business administrations of the chinese electronics bank will come into effect on march 1 . ASTfeature new rules for business management of china s electronic banking industry to come into effect on march 1 Table 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese word zhongguo with its synonym BLEU points can be observed . ASTfeature can obtain slightly better performance . Our NMT system outperforms the NMT system GNMT with BLEU point and performs comparably with Gehring et al . 2017 which is based on CNN with 15 layers . Given that our approach can be applied to any NMT systems we expect that the adversarial stability training mechanism can further improve performance upon the advanced NMT architectures . We leave this for future work . IWSLT Translation Table 4 shows the results on IWSLT EnglishFrench Translation . Compared with our strong baseline system trained by MLE we observe that our models consistently improve translation performance in all datasets . ASTfeature can achieve significant improvements on the tst2015 although ASTlexical obtains comparable results . These demonstrate that our approach maintains good performance on the text . Results on Synthetic Perturbed Data In order to investigate the ability of our training approaches to deal with perturbations we experiment with three types of synthetic perturbations: Swap: We randomly choose N positions from a sentence and then swap the chosen words with their right neighbours . Replacement: We randomly replace sampled words in the sentence with other words . Deletion: We randomly delete N words from each sentence in the dataset . As shown in Table 5 we can find that our training approaches ASTlexical and ASTfeature consistently outperform MLE against perturbations on all the numbers of operations . This means that our 1763 Ltrue Lnoisy Ladv BLEU Table 7: Ablation study of adversarial stability training ASTlexical on translation . means the loss function is included in the training objective while means it is not . approaches have the capability of resisting perturbations . Along with the number of operations increasing the performance on MLE drops quickly . Although the performance of our approaches also drops we can see that our approaches consistently surpass MLE . In ASTlexical with 0 operation the difference is for all synthetic types but the differences are enlarged to and respectively for the three types with 5 operations . In the Swap and Deletion types ASTlexical and ASTfeature perform comparably after more than four operations . Interestingly ASTlexical performs significantly better than both of MLE and ASTfeature after more than one operation in the Replacement type . This is because ASTlexical trains the model specifically on perturbation data that is constructed by replacing words which agrees with the Replacement Type . Overall ASTlexical performs better than ASTfeature against perturbations after multiple operations . We speculate that the perturbation method for ASTlexical and synthetic type are both discrete and they keep more consistent . Table 6 shows example translations of a Chinese sentence and its perturbed counterpart . These findings indicate that we can construct specific perturbations for a particular task . For example in simultaneous translation an automatic speech recognition system usually generates wrong words with the same pronunciation of correct words which dramatically affects the quality of machine translation system . Therefore we can design specific perturbations aiming for this task . Analysis Ablation Study Our training objective function Eq . 4 contains three loss functions . We perform an ablation Iterations 0 20 40 60 80 100 120 140 160 180 200 BLEU 34 36 38 40 42 44 46 103 ASTlexical ASTfeature Figure 2: BLEU scores of ASTlexical over iterations on validation set . Iterations 0 50 100 150 200 Cost 1 2 3 4 5 103 L noisy L true L inv Figure 3: Learning curves of three loss functions Ltrue Linv and Lnoisy over iterations on ChineseEnglish validation set . study on the translation to understand the importance of these loss functions by choosing ASTlexical as an example . As Table 7 shows if we remove Ladv the translation performance decreases by BLEU point . However when Lnoisy is excluded from the training objective function it results in a significant drop of BLEU point . Surprisingly only using Lnoisy is able to lead to an increase of BLEU point . BLEU Scores over Iterations Figure 2 shows the changes of BLEU scores over iterations respectively for ASTlexical and ASTfeature . They behave nearly consistently . Initialized by the model trained by MLE their performance drops rapidly . Then it starts to go up quickly . Compared with the starting point the 1764 maximal dropping points reach up to about BLEU points . Basically the curves present the state of oscillation . We think that introducing random perturbations and adversarial learning can make the training not very stable like MLE . Learning Curves of Loss Functions Figure 3 shows the learning curves of three loss functions Ltrue Linv and Lnoisy . We can find that their costs of loss functions decrease not steadily . Similar to the Figure 2 there still exist oscillations in the learning curves although they do not change much sharply . We find that Linv converges to around after about 100K iterations which indicates that discriminator outputs probability for both positive and negative samples and it cannot distinguish them . Thus the behaviors of the encoder for x and its perturbed neighbour x 0 perform nearly consistently . 5 Related Work Our work is inspired by two lines of research : 1 adversarial learning and 2 data augmentation . Adversarial Learning Generative Adversarial Network GAN Goodfellow et 2014 and its related derivative have been widely applied in computer vision Radford et 2015 Salimans et 2016 and natural language processing Li et 2017 Yang et 2018 . Previous work has constructed adversarial examples to attack trained networks and make networks resist them which has proved to improve the robustness of networks Goodfellow et 2015 Miyato et 2016 Zheng et 2016 . Belinkov and Bisk 2018 introduce adversarial examples to training data for NMT models . In contrast to theirs adversarial stability training aims to stabilize both the encoder and decoder in NMT models . We adopt adversarial learning to learn the encoder . Data Augmentation Data augmentation has the capability to improve the robustness of NMT models . In NMT there is a number of work that augments the training data with monolingual corpora Sennrich et 2016a Cheng et 2016 He et 2016a Zhang and Zong 2016 . They all leverage complex models such as inverse NMT models to generate translation equivalents for monolingual corpora . Then they augment the parallel corpora with these pseudo corpora to improve NMT models . Some authors have recently endeavored to achieve NMT through transferring knowledge from bilingual corpora of other language pairs Chen et 2017 Zheng et 2017 Cheng et 2017 or monolingual corpora Lample et 2018 Artetxe et 2018 . Our work significantly differs from these work . We do not resort to any complicated models to generate perturbed data and do not depend on extra monolingual or bilingual corpora . The way we exploit is more convenient and easy to implement . We focus more on improving the robustness of NMT models . 6 Conclusion We have proposed adversarial stability training to improve the robustness of NMT models . The basic idea is to train both the encoder and decoder robust to input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart . We propose two approaches to construct perturbed data to adversarially train the encoder and stabilize the decoder . Experiments on and translation tasks show that the proposed approach can improve both the robustness and translation performance . As our training framework is not limited to specific perturbation types it is interesting to evaluate our approach in natural noise existing in practical applications such as homonym in the simultaneous translation system . It is also necessary to further validate our approach on more advanced NMT architectures such as NMT Gehring et 2017 and Transformer Vaswani et 2017 . Acknowledgments We thank the anonymous reviewers for their insightful comments and suggestions . We also thank Xiaoling Li for analyzing experimental results and providing valuable examples . Yang Liu is supported by the National Key R D Program of China No . 2017YFB0202204 National Natural Science Foundation of China No . 61761166008 No . 61522204 Beijing Advanced Innovation Center for Language Resources and the project supported by the National Research Foundation Prime Ministers Office Singapore under its IRC Singapore Funding Initiative . 1765